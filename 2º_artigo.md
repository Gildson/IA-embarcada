2º artigo
Título: TinyMLOps: Operational Challenges for Widespread Edge AI Adoption

O artigo TinyMLOps: desafios operacionais para adoção generalizada de IA de borda traz os desafios enfrentados quando passa-se de um aplicativo centralizado baseado em nuvem para uma implantação descentralizada baseada em borda, desafios esses diferentes do que já estamos acostumados a ouvir como por exemplo, o consumo de energia e a capacidade de processamento, ao longo do artigo encontramos desafios bem específicos sobre como lidar com dispositivos fragmentados, proteção de propriedade intelectual e validação dos resultados de um modelo. Durante a produção do artigo há uma defesa da extensão do MLOps para o TinyMLOps e essa extensão são as gerados dos desafios descritos. O primeiro desafio enfrentado é o gerenciamento de versões, a centralização baseada em nuvem permite que um único modelo seja suficiente para todos os usuários já para uma aplicação descentralizada e baseada na borda, onde cada dispositivos tem suas características pode haver a necessidade de dar suporte a vários modelos. O segundo desafio é a observabilidade, com os modelos de ML chegando a cada vez mais consumidores a manutenção e a observabilidade são fundamentais para manter os modelos funcionando conforme o esperado e nesse contexto a falta de conhecimento sobre todos os dados que estão em cada borda dificulta a detecção de anomalias. O terceiro desafio é o tipo de modelo de negócio, onde a forma de negócio atual do MLOps pode até ser implantada no tinyMLOps mais enfrenta problemas como o usuário final não está conectado a internet, por exemplo. O quarto desafio é o retreinamento e personalização dos modelos, um ponto forte da aplicação na borda é a privacidade dos dados já que os dados permanecem no dispositivo, mas isso significa que é impossível centralizar todos os dados para treinar novos modelos, uma alternativa para esse desafio é a implementação do aprendizado federado, onde o usuário baixa as atualizações e treina com seus próprios dados e envia para a nuvem as atualizações do modelo porém isso pode aumenta o consumo de energia. O quinto desafio é a fragmentação de IoT, a variedade de dispositivos diferentes, cada um com suporte de software e recursos de hardware diferentes, isso deixa a implementação do modelo em um novo dispositivo mais custosa e mais cara, solução para a fragmentação é o empacotamento de micro serviços fracamente acoplados executados como containeres. O sexto desafio é a proteção da propriedade intelectual, segundo o autor do artigo, Um modelo de aprendizado de máquina treinado pode representar um valor intelectual significativo para o proprietário. Parte desse valor vem do conjunto de habilidades altamente especializado do desenvolvedor que gastou uma grande quantidade de tentativa e erro desenvolvendo e ajustando o modelo, especialmente se o modelo precisa ser otimizado para implantação de borda. Além disso, treinar o próprio modelo requer acesso a recursos de computação poderosos. Não é difícil ver modelos que levaram dias e até semanas para serem treinados. Essa apropriação pode ser dividida em dois grupo, primeiro o roubo do modelo de ML de forma direta, onde o invasor consegue de alguma forma obter os pesos treinados exatos do modelo e segundo o roubo do modelo de ML de forma indireta, onde o invasor pode extrair propriedades intelectuais valiosas essa possível falta de segurança é devido a apĺicação ser na borda a propriedade intelectual, a implementação do código, e os dados, ficam no dispositivos, facilitando que usuários mal intencionados apropriem se de forma inadequada dos dados gerados e do código implementado. O último desafio é a execução verificável em dispositivos não confiáveis, Um usuário mal-intencionado pode alterar o modelo ou as previsões para induzir o sistema a pensar que certas condições foram atendidas. Existem etapas que podem ser usadas para verificação mas elas podem causar sobrecarga. os desafios apresentados ainda podem ser apenas o começo na caminhada da descentralização dos modelos de ML.
